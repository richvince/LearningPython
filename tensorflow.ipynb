{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gold': 43, 'show': 57, 'consolidated': 45, 'results': 46, 'years': 9, 'bring': 47, 'university<eos>the': 48, 'rubens': 49, 'including': 50, 'filters': 10, 'its': 51, 'before': 52, 'centrust': 147, 'enters': 53, 'group': 54, 'surviving': 55, 'banknote': 56, 'workers': 15, 'than': 16, 'symptoms': 58, 'to': 6, 'now<eos>neither': 59, 'board': 60, 'caused': 61, 'has': 62, 'decades': 63, 'risk': 65, 'asbestos': 7, 'rake': 66, 'ipo': 135, 'early': 68, 'five': 69, 'closely': 70, 'swapo': 104, 'schools': 71, 'using': 72, 'corp.': 73, 'nor': 74, 'aer': 76, 'fields': 77, 'fromstein': 78, 'whether': 79, 'paper': 80, 'stopped': 81, 'reported<eos>the': 82, 'james': 83, 'university': 84, 'old': 18, 'billion': 85, 'findings': 86, 'exposed': 87, 'national': 88, 'calloway': 89, 'likely': 90, 'are': 91, 'N<eos>mr.': 92, 'our': 93, 'even': 94, 'will': 163, 'said': 19, 'appear': 97, 'for': 98, 'brief': 99, 'gitano': 100, 'research': 101, 'kent': 11, 'dutch': 102, 'medicine': 103, 'new': 17, 'cigarettes<eos>we': 105, 'journal': 113, 'wachter<eos>pierre': 107, 'story<eos>we': 108, 'fiber': 109, 'recently': 96, 'said<eos>among': 111, 'N<eos>from': 112, 'sold': 106, 'team': 64, 'reported': 115, 'punts': 116, 'plc': 117, 'unusually': 167, 'n.v.': 139, 'on': 26, 'about': 120, 'substance': 121, 'forum': 122, 'institute': 123, 'of': 2, 'studied': 124, 'british': 125, 'times': 126, 'harvard': 127, 'products': 128, 'smokers': 129, 'makes': 130, 'among': 131, 'named': 132, 'industrial': 133, 'useful': 134, 'cancer': 20, 'N<eos>although': 67, 'berlitz': 136, 'england': 137, 'unit': 138, 'from': 119, 'publishing': 140, 'snack-food': 141, 'institute<eos>dr.': 142, 'three': 27, 'anyone': 143, 'type': 144, 'expected': 145, 'percentage': 146, 'was': 30, 'said<eos><unk>': 148, 'conglomerate<eos>a': 149, 'more': 21, 'questionable': 150, 'a': 3, '1950s': 151, 'form': 152, 'that': 28, 'company': 153, 'regatta': 154, 'number<eos>four': 155, 'N': 4, 'former': 157, 'worked': 156, 'with': 8, 'nahb': 44, 'guterman': 158, 'nov.': 159, 'join': 160, 'talking': 176, 'this': 29, 'problem<eos>a': 75, 'up': 162, 'spokeswoman': 95, \"'re\": 164, 'replaced': 165, 'today': 166, 'attention': 114, 'were': 22, 'making': 118, 'mlx': 168, 'led': 110, '<unk>': 0, 'and': 12, 'exposures': 169, 'hydro-quebec': 171, 'deaths': 172, 'boston': 31, 'is': 13, 'year': 173, 'it': 23, 'an': 174, 'high': 175, 'heard': 161, 'as': 177, 'at': 178, 'have': 24, 'in': 5, 'memotec': 179, 'any': 32, 'diseases': 180, 'group<eos>rudolph': 181, 'different': 182, 'properties<eos>there': 183, 'no': 33, 'amounts': 184, 'york-based': 185, 'make': 186, 'nonexecutive': 34, 'very': 187, 'causing': 188, 'chairman': 35, 'sim': 189, 'used': 36, \"'s\": 37, 'users': 190, 'information': 191, 'who': 38, 'cluett': 192, 'a.': 193, 'director': 39, 'cigarette': 40, 'modest': 194, 'cancer<eos>': 170, 'men': 195, 'preliminary': 196, 'kia': 197, 'aware': 198, 'ssangyong': 199, 'died': 200, 'ago': 25, 'medical': 201, 'later': 202, 'cigarettes': 41, 'inc.': 203, 'the': 1, 'latest': 204, 'having': 205, 'researchers': 14, 'once': 42}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "\n",
    "def _read_words(filename):\n",
    "  with gfile.GFile(filename, \"r\") as f:\n",
    "    return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "data = _read_words('data/chars.txt')\n",
    "counter = collections.Counter(data)\n",
    "count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "words, _ = list(zip(*count_pairs))\n",
    "word_to_id = dict(zip(words, range(len(words))))\n",
    "print(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "data = _read_words('data/chars.txt')\n",
    "ids = [word_to_id[word] for word in data]\n",
    "print(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "raw_data = np.array(ids, dtype=np.int32)\n",
    "data_len = len(raw_data)\n",
    "print(data_len)\n",
    "batch_len = data_len // 30\n",
    "print(batch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 76  56 136  89 147 192  78 100 158 171 135 197 179 168  44 116  66 154\n",
      "  49 189 141 199 104 107   0   4   9  18 163 160   1  60 177   3  34  39\n",
      " 159  92   0  13  35   2   0 139   1 102 140 181   0   4   9  18  12 157\n",
      "  35   2  45  43  77 117  30 132   3  34  39   2  29 125 133 149 152   2\n",
      "   7  42  36   6 186  11  40  10  62  61   3 175 146   2  20 172 131   3\n",
      "  54   2  15  87   6  23  21  16   4   9  25  14  82   7 109   0  13 167\n",
      "   0  42  23  53   1   0   8  94  99 169   6  23 188  58  28  57 162  63\n",
      " 202  14 148 203   1 138   2  17 185   0  73  28 130  11  41  81  72   0\n",
      "   5  51   0  40  10   5  67 196  86  22 115  21  16   3 173  25   1 204\n",
      "  46  97   5 166  37  17 137 113   2 103   3 122  90   6  47  17 114   6\n",
      "   1  75   0   0  19  29  13 174  18 108 164 176 120   9  25  52 143 161\n",
      "   2   7 205  32 150 183  13  33   7   5  93 128  59   0  74   1  14  38\n",
      " 124   1  15  22 198   2  32 101  26 129   2   1  11 105  24  33 134 191\n",
      "  26  79 190  91 178  65  19  83 193   0   2  31  37   0  20 142   0 110\n",
      "   3  64   2  14 119   1  88  20 123  12   1 201  71   2 127  84  12  31\n",
      "  48   0  95  19   7  30  36   5 187 194 184   5 118  80  98   1  10   5\n",
      "   1  68 151  12 165   8   3 182 144   2   0   5 112   4   6   4   4  85\n",
      "  11  41   8   1  10  22 106   1 153 111   4 195  38 156  70   8   1 121\n",
      "   4  24 200  21  16  27 126   1 145 155   2   1  69  55  15  24   0 180\n",
      "  50  27   8  96   0 170]\n",
      "[ 76  56 136  89 147 192  78 100 158 171 135]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "iter_data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
    "print(raw_data)\n",
    "print(raw_data[batch_len * 0:batch_len * (0 + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    iter_data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n",
    "num_steps = 3\n",
    "epoch_size = (batch_len - 1) // num_steps\n",
    "print(epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76  56 136]\n",
      " [197 179 168]\n",
      " [104 107   0]\n",
      " [  3  34  39]\n",
      " [  1 102 140]\n",
      " [  2  45  43]\n",
      " [ 29 125 133]\n",
      " [ 11  40  10]\n",
      " [131   3  54]\n",
      " [  9  25  14]\n",
      " [ 23  53   1]\n",
      " [ 58  28  57]\n",
      " [  2  17 185]\n",
      " [  0   5  51]\n",
      " [115  21  16]\n",
      " [166  37  17]\n",
      " [ 47  17 114]\n",
      " [174  18 108]\n",
      " [  2   7 205]\n",
      " [128  59   0]\n",
      " [198   2  32]\n",
      " [ 33 134 191]\n",
      " [193   0   2]\n",
      " [ 64   2  14]\n",
      " [ 71   2 127]\n",
      " [ 30  36   5]\n",
      " [ 10   5   1]\n",
      " [  2   0   5]\n",
      " [  8   1  10]\n",
      " [156  70   8]]\n"
     ]
    }
   ],
   "source": [
    "print(iter_data[:, 0*num_steps:(0+1)*num_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(epoch_size):\n",
    "    x = iter_data[:, i*num_steps:(i+1)*num_steps]\n",
    "    y = iter_data[:, i*num_steps+1:(i+1)*num_steps+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
